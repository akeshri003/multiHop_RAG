{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e9d23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\r\n",
      "You should consider upgrading via the '/Users/aryankeshri/Downloads/Entivin_Task/lang_graph_rag/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U --quiet langchain-community tiktoken langchain-openai langchainhub chromadb langchain langgraph langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b59ea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"multihop-rag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b897f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "# LANGCHAIN_TRACING_V2=True\n",
    "# LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "# LANGCHAIN_API_KEY=\"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\"\n",
    "LANGCHAIN_PROJECT=\"multihop-rag\"\n",
    "tracer = LangChainTracer()\n",
    "tracer.run_name = \"multihop-rag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e422a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "file_path = \"/Users/aryankeshri/Downloads/Entivin_Task/Resources/Multihop_QA.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "769f1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pages)\n",
    "# print(f\"{pages[4].metadata}\\n\")\n",
    "# print(pages[4].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7bab9381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7405\n",
      "2962\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "import json\n",
    "\n",
    "with open('./hotpot_dev_distractor_v1.json', 'r') as fp:\n",
    "    dataset = json.load(fp)\n",
    "print(len(dataset))\n",
    "print(round(0.40*len(dataset)))\n",
    "dataset = dataset[:round(0.40*len(dataset))]\n",
    "# # print(f\"new_length: {len(dataset)}\")\n",
    "keys_pop = [\"answer\", \"question\"]\n",
    "\n",
    "qa_dict = []\n",
    "\n",
    "for d in dataset:\n",
    "    quest = d[\"question\"]\n",
    "    ans = d[\"answer\"]\n",
    "    \n",
    "    qa_dict.append({\n",
    "        \"id\": d[\"_id\"],\n",
    "        \"question\": [quest],\n",
    "        \"answer\": ans\n",
    "    })\n",
    "    \n",
    "    for key in keys_pop:\n",
    "        d.pop(key, None)\n",
    "# print(qa_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cd85da",
   "metadata": {},
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d992b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2962\n",
      "2962\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "\n",
    "\n",
    "# Create a Document object\n",
    "# include metadata\n",
    "documents = []\n",
    "print(len(dataset))\n",
    "for item in dataset:\n",
    "    # Combine context sections into a single string for better embeddings\n",
    "    context = item.get(\"context\", [])\n",
    "    page_content = \"\"\n",
    "    for section in context:\n",
    "        section_title = section[0]\n",
    "        section_texts = section[1]\n",
    "        # Concatenate title and its corresponding texts\n",
    "        page_content += f\"{section_title}: \" + \" \".join(section_texts) + \"\\n\"\n",
    "\n",
    "    # Create a Document object with the combined context and _id as metadata\n",
    "    doc = Document(\n",
    "        page_content=page_content,\n",
    "        metadata={\n",
    "            \"_id\": item[\"_id\"]\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fce85972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original token count: 2747347\n",
      "Final token count: 949112\n",
      "Final dataset size: 1029\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Function to calculate token usage\n",
    "def calculate_total_tokens(documents, chunk_size):\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=chunk_size, chunk_overlap=0\n",
    "    )\n",
    "    token_count = 0\n",
    "    for doc in documents:\n",
    "        chunks = text_splitter.split_text(doc.page_content)\n",
    "        token_count += sum(len(chunk.split()) for chunk in chunks)  # Approximate token count\n",
    "    return token_count\n",
    "\n",
    "# Initial dataset size\n",
    "original_tokens = calculate_total_tokens(documents, chunk_size=250)\n",
    "print(f\"Original token count: {original_tokens}\")\n",
    "\n",
    "# Reduce dataset until it's within the token limit\n",
    "while original_tokens > 1_000_000:\n",
    "    documents = documents[:int(len(documents) * 0.9)]  # Reduce by 10% iteratively\n",
    "    original_tokens = calculate_total_tokens(documents, chunk_size=250)\n",
    "\n",
    "print(f\"Final token count: {original_tokens}\")\n",
    "print(f\"Final dataset size: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa1429f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(documents):\n\u001b[0;32m---> 16\u001b[0m     chunked_texts \u001b[38;5;241m=\u001b[39m \u001b[43mtext_splitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunked_texts:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# Create Document object for each chunk with metadata\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         chunks\u001b[38;5;241m.\u001b[39mappend(Document(page_content\u001b[38;5;241m=\u001b[39mchunk, metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_doc_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: idx}))\n",
      "File \u001b[0;32m~/Downloads/Entivin_Task/lang_graph_rag/lib/python3.9/site-packages/langchain_text_splitters/character.py:126\u001b[0m, in \u001b[0;36mRecursiveCharacterTextSplitter.split_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Split the input text into smaller chunks based on predefined separators.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m        List[str]: A list of text chunks obtained after splitting.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_separators\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Entivin_Task/lang_graph_rag/lib/python3.9/site-packages/langchain_text_splitters/character.py:88\u001b[0m, in \u001b[0;36mRecursiveCharacterTextSplitter._split_text\u001b[0;34m(self, text, separators)\u001b[0m\n\u001b[1;32m     86\u001b[0m     separator \u001b[38;5;241m=\u001b[39m _s\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_separator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     89\u001b[0m     separator \u001b[38;5;241m=\u001b[39m _s\n\u001b[1;32m     90\u001b[0m     new_separators \u001b[38;5;241m=\u001b[39m separators[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/re.py:201\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "import time\n",
    "\n",
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=50\n",
    ")\n",
    "\n",
    "# Split documents into chunks\n",
    "chunks = []\n",
    "for idx, doc in enumerate(documents):\n",
    "    chunked_texts = text_splitter.split_text(doc)\n",
    "    for chunk in chunked_texts:\n",
    "        # Create Document object for each chunk with metadata\n",
    "        chunks.append(Document(page_content=chunk, metadata={\"source_doc_id\": idx}))\n",
    "\n",
    "# Monitor token usage\n",
    "total_tokens = sum(len(chunk.page_content.split()) for chunk in chunks)\n",
    "print(f\"Total tokens in dataset: {total_tokens}\")\n",
    "\n",
    "# Initialize ChatOpenAI embeddings\n",
    "embedding_model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Initialize the Chroma vector store\n",
    "vectorstore = Chroma(collection_name=\"chat-chroma\", embedding_function=embedding_model)\n",
    "\n",
    "# Batch size for processing\n",
    "batch_size = 50  # Number of chunks per batch\n",
    "\n",
    "# Process and add documents to vector store in batches\n",
    "for i in range(0, len(chunks), batch_size):\n",
    "    batch = chunks[i:i + batch_size]\n",
    "\n",
    "    # Extract content and metadata for embeddings\n",
    "    batch_texts = [doc.page_content for doc in batch]\n",
    "    batch_metadatas = [doc.metadata for doc in batch]\n",
    "\n",
    "    # Generate embeddings and add to vector store\n",
    "    vectorstore.add_texts(texts=batch_texts, metadatas=batch_metadatas)\n",
    "    \n",
    "    # Sleep to avoid exceeding rate limits (adjust as needed)\n",
    "    time.sleep(60)\n",
    "\n",
    "print(\"All documents have been successfully added to the vector store.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eab148",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c301b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryankeshri/Downloads/Entivin_Task/lang_graph_rag/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/var/folders/_4/ky3k7xbn09562xrb4g_gkbsc0000gn/T/ipykernel_69167/1919133848.py:35: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(question)\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'_id': '5a8c7595554299585d9e36b6'}, page_content='{\\n    \"_id\": \"5a8c7595554299585d9e36b6\",\\n    \"supporting_facts\": [\\n        [\\n            \"Kiss and Tell (1945 film)\",\\n            0\\n        ],\\n        [\\n            \"Shirley Temple\",\\n            0\\n        ],\\n        [\\n            \"Shirley Temple\",\\n            1\\n        ]\\n    ],\\n    \"context\": [\\n        [\\n            \"Meet Corliss Archer\",\\n            [\\n                \"Meet Corliss Archer, a program from radio\\'s Golden Age, ran from January 7, 1943 to September 30, 1956.\",\\n                \"Although it was CBS\\'s answer to NBC\\'s popular \\\\\"A Date with Judy\\\\\", it was also broadcast by NBC in 1948 as a summer replacement for \\\\\"The Bob Hope Show\\\\\".\",\\n                \"From October 3, 1952 to June 26, 1953, it aired on ABC, finally returning to CBS.\",\\n                \"Despite the program\\'s long run, fewer than 24 episodes are known to exist.\"\\n            ]\\n        ],\\n        [\\n            \"Shirley Temple\",\\n            [\\n                \"Shirley Temple Black (April 23, 1928 \\\\u2013 February 10, 2014) was an American actress, singer, dancer, businesswoman, and diplomat who was Hollywood\\'s number one box-office draw as a child actress from 1935 to 1938.\",\\n                \"As an adult, she was named United States ambassador to Ghana and to Czechoslovakia and also served as Chief of Protocol of the United States.\"\\n            ]\\n        ],\\n        [\\n            \"Janet Waldo\",\\n            [\\n                \"Janet Marie Waldo (February 4, 1920 \\\\u2013 June 12, 2016) was an American radio and voice actress.\",\\n                \"She is best known in animation for voicing Judy Jetson, Nancy in \\\\\"Shazzan\\\\\", Penelope Pitstop, and Josie in \\\\\"Josie and the Pussycats\\\\\", and on radio as the title character in \\\\\"Meet Corliss Archer\\\\\".\"\\n            ]\\n        ]\\n    ],\\n    \"type\": \"bridge\",\\n    \"level\": \"hard\"\\n}')]\n",
      "{\n",
      "    \"_id\": \"5a8c7595554299585d9e36b6\",\n",
      "    \"supporting_facts\": [\n",
      "        [\n",
      "            \"Kiss and Tell (1945 film)\",\n",
      "            0\n",
      "        ],\n",
      "        [\n",
      "            \"Shirley Temple\",\n",
      "            0\n",
      "        ],\n",
      "        [\n",
      "            \"Shirley Temple\",\n",
      "            1\n",
      "        ]\n",
      "    ],\n",
      "    \"context\": [\n",
      "        [\n",
      "            \"Meet Corliss Archer\",\n",
      "            [\n",
      "                \"Meet Corliss Archer, a program from radio's Golden Age, ran from January 7, 1943 to September 30, 1956.\",\n",
      "                \"Although it was CBS's answer to NBC's popular \\\"A Date with Judy\\\", it was also broadcast by NBC in 1948 as a summer replacement for \\\"The Bob Hope Show\\\".\",\n",
      "                \"From October 3, 1952 to June 26, 1953, it aired on ABC, finally returning to CBS.\",\n",
      "                \"Despite the program's long run, fewer than 24 episodes are known to exist.\"\n",
      "            ]\n",
      "        ],\n",
      "        [\n",
      "            \"Shirley Temple\",\n",
      "            [\n",
      "                \"Shirley Temple Black (April 23, 1928 \\u2013 February 10, 2014) was an American actress, singer, dancer, businesswoman, and diplomat who was Hollywood's number one box-office draw as a child actress from 1935 to 1938.\",\n",
      "                \"As an adult, she was named United States ambassador to Ghana and to Czechoslovakia and also served as Chief of Protocol of the United States.\"\n",
      "            ]\n",
      "        ],\n",
      "        [\n",
      "            \"Janet Waldo\",\n",
      "            [\n",
      "                \"Janet Marie Waldo (February 4, 1920 \\u2013 June 12, 2016) was an American radio and voice actress.\",\n",
      "                \"She is best known in animation for voicing Judy Jetson, Nancy in \\\"Shazzan\\\", Penelope Pitstop, and Josie in \\\"Josie and the Pussycats\\\", and on radio as the title character in \\\"Meet Corliss Archer\\\".\"\n",
      "            ]\n",
      "        ]\n",
      "    ],\n",
      "    \"type\": \"bridge\",\n",
      "    \"level\": \"hard\"\n",
      "}\n",
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "# question = \"What are Multihop RAG?\"\n",
    "question = \"What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "print(docs)\n",
    "doc_txt = docs[0].page_content\n",
    "# doc_txt = doc.context[]\n",
    "print(doc_txt)\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd20ba53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shirley Temple held the government position of United States ambassador to Ghana and to Czechoslovakia, as well as Chief of Protocol of the United States.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31a3cb2",
   "metadata": {},
   "source": [
    "## Make tool\n",
    "\n",
    "make tool for your multihop rag here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85bf1b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Who portrayed Corliss Archer in the film Kiss and Tell?\\n2. What government position did the woman who portrayed Corliss Archer hold?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question Decomposer\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a question decomposer that decomposes a question into 2 or 3 sub-questions, if the original question is complex or indirect or not straightforward.\\n\n",
    "Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "\n",
    "requery_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Decompose into two or three sub-question as per the requirement.\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_decomposer = requery_prompt | llm | StrOutputParser()\n",
    "question_decomposer.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b4f8f9",
   "metadata": {},
   "source": [
    "## Create graphs\n",
    "\n",
    "Now let's create our graph for implementing multi-hop features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c41f6",
   "metadata": {},
   "source": [
    "### Define Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "736620ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Set\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph. \n",
    "    \n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        iterative_Search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "    \n",
    "    questions: List[str]\n",
    "    generation: str\n",
    "    requery_search: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb75aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "    \n",
    "    Args: \n",
    "        state (dict): The current graph state\n",
    "        \n",
    "    Returns: \n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"--Retrieve--\\n\")\n",
    "    documents = []\n",
    "    questions = state['questions']\n",
    "    \n",
    "    for question in questions:\n",
    "        # Retrieval \n",
    "        documents.extend(retriever.get_relevant_documents(question))\n",
    "        \n",
    "    return {\"documents\": documents, \"questions\": questions}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate Answer: \n",
    "    \n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "        \n",
    "    Returns: \n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---Generate---\\n\")\n",
    "    \n",
    "    questions = state['questions']\n",
    "    documents = state['documents']\n",
    "    generation = \"\"\n",
    "    # RAG generation\n",
    "    print(documents)\n",
    "    for question in questions:\n",
    "        generation = generation + rag_chain.invoke({'context': documents, 'question': question})\n",
    "        \n",
    "    return {\"documents\": documents, \"questions\": questions[0], \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "    \n",
    "    Args: \n",
    "        state (dict): The current graph state\n",
    "    \n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---Check Document Relevance to Question---\\n\")\n",
    "    question = state[\"questions\"]\n",
    "    documents = state[\"documents\"]\n",
    "    print(documents)\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    re_query = \"No\"\n",
    "    for d in documents: # Its a single loop cause, in the begining there is only one question in the list. and this function is called only in the begining\n",
    "\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\\n\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\\n\")\n",
    "            re_query = \"Yes\"\n",
    "            continue\n",
    "#         else:\n",
    "#             print(\"---No relevant document found---\\n\")\n",
    "#             re_query = \"Yes\"\n",
    "    return {\"documents\": filtered_docs, \"questions\": question, \"requery_search\": re_query}\n",
    "\n",
    "\n",
    "def decompose_query(state):\n",
    "    \"\"\"\n",
    "    Decompose the query into sub-queries for better retrieval.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appends multiple questions to questions key with a re-phrased question\n",
    "    \"\"\"\n",
    "    print(\"---Decompose Query---\\n\")\n",
    "    question = state['questions'][0]\n",
    "    \n",
    "    # Decomposed questions \n",
    "    questions_str = question_decomposer.invoke({\"question\": question})\n",
    "    print(questions_str)\n",
    "    print(\"\\n\")\n",
    "    new_questions = questions_str.split('\\n')\n",
    "    \n",
    "    return {\"documents\": documents, \"questions\": new_questions}\n",
    "\n",
    "def decide_requery(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or decompose a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "    print(\"---Assesing Graded Documents---\\n\")\n",
    "    state['questions']\n",
    "    requery = state['requery_search']\n",
    "    state['documents']\n",
    "    \n",
    "    if requery == \"Yes\":\n",
    "        print(\"---Decomposing Question into sub-questions---\\n\")\n",
    "        return \"decompose_query\"\n",
    "    else:\n",
    "        print(\"---Decision Generate---\\n\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f894209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve) # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"decompose_query\", decompose_query)\n",
    "workflow.add_node(\"retrieve_after_decomposition\", retrieve)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "# workflow.add_node(\"\")\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_requery,\n",
    "    {\n",
    "        \"decompose_query\": \"decompose_query\",\n",
    "        \"generate\": \"generate\"\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"decompose_query\", \"retrieve_after_decomposition\")\n",
    "workflow.add_edge(\"retrieve_after_decomposition\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca563e9",
   "metadata": {},
   "source": [
    "## Use the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "786e357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Retrieve--\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "---Check Document Relevance to Question---\n",
      "\n",
      "[Document(metadata={'_id': '5a8c7595554299585d9e36b6'}, page_content='{\\n    \"_id\": \"5a8c7595554299585d9e36b6\",\\n    \"supporting_facts\": [\\n        [\\n            \"Kiss and Tell (1945 film)\",\\n            0\\n        ],\\n        [\\n            \"Shirley Temple\",\\n            0\\n        ],\\n        [\\n            \"Shirley Temple\",\\n            1\\n        ]\\n    ],\\n    \"context\": [\\n        [\\n            \"Meet Corliss Archer\",\\n            [\\n                \"Meet Corliss Archer, a program from radio\\'s Golden Age, ran from January 7, 1943 to September 30, 1956.\",\\n                \"Although it was CBS\\'s answer to NBC\\'s popular \\\\\"A Date with Judy\\\\\", it was also broadcast by NBC in 1948 as a summer replacement for \\\\\"The Bob Hope Show\\\\\".\",\\n                \"From October 3, 1952 to June 26, 1953, it aired on ABC, finally returning to CBS.\",\\n                \"Despite the program\\'s long run, fewer than 24 episodes are known to exist.\"\\n            ]\\n        ],\\n        [\\n            \"Shirley Temple\",\\n            [\\n                \"Shirley Temple Black (April 23, 1928 \\\\u2013 February 10, 2014) was an American actress, singer, dancer, businesswoman, and diplomat who was Hollywood\\'s number one box-office draw as a child actress from 1935 to 1938.\",\\n                \"As an adult, she was named United States ambassador to Ghana and to Czechoslovakia and also served as Chief of Protocol of the United States.\"\\n            ]\\n        ],\\n        [\\n            \"Janet Waldo\",\\n            [\\n                \"Janet Marie Waldo (February 4, 1920 \\\\u2013 June 12, 2016) was an American radio and voice actress.\",\\n                \"She is best known in animation for voicing Judy Jetson, Nancy in \\\\\"Shazzan\\\\\", Penelope Pitstop, and Josie in \\\\\"Josie and the Pussycats\\\\\", and on radio as the title character in \\\\\"Meet Corliss Archer\\\\\".\"\\n            ]\\n        ]\\n    ],\\n    \"type\": \"bridge\",\\n    \"level\": \"hard\"\\n}')]\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "\n",
      "---Assesing Graded Documents---\n",
      "\n",
      "---Decision Generate---\n",
      "\n",
      "\"Node 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "---Generate---\n",
      "\n",
      "[Document(metadata={'_id': '5a8c7595554299585d9e36b6'}, page_content='{\\n    \"_id\": \"5a8c7595554299585d9e36b6\",\\n    \"supporting_facts\": [\\n        [\\n            \"Kiss and Tell (1945 film)\",\\n            0\\n        ],\\n        [\\n            \"Shirley Temple\",\\n            0\\n        ],\\n        [\\n            \"Shirley Temple\",\\n            1\\n        ]\\n    ],\\n    \"context\": [\\n        [\\n            \"Meet Corliss Archer\",\\n            [\\n                \"Meet Corliss Archer, a program from radio\\'s Golden Age, ran from January 7, 1943 to September 30, 1956.\",\\n                \"Although it was CBS\\'s answer to NBC\\'s popular \\\\\"A Date with Judy\\\\\", it was also broadcast by NBC in 1948 as a summer replacement for \\\\\"The Bob Hope Show\\\\\".\",\\n                \"From October 3, 1952 to June 26, 1953, it aired on ABC, finally returning to CBS.\",\\n                \"Despite the program\\'s long run, fewer than 24 episodes are known to exist.\"\\n            ]\\n        ],\\n        [\\n            \"Shirley Temple\",\\n            [\\n                \"Shirley Temple Black (April 23, 1928 \\\\u2013 February 10, 2014) was an American actress, singer, dancer, businesswoman, and diplomat who was Hollywood\\'s number one box-office draw as a child actress from 1935 to 1938.\",\\n                \"As an adult, she was named United States ambassador to Ghana and to Czechoslovakia and also served as Chief of Protocol of the United States.\"\\n            ]\\n        ],\\n        [\\n            \"Janet Waldo\",\\n            [\\n                \"Janet Marie Waldo (February 4, 1920 \\\\u2013 June 12, 2016) was an American radio and voice actress.\",\\n                \"She is best known in animation for voicing Judy Jetson, Nancy in \\\\\"Shazzan\\\\\", Penelope Pitstop, and Josie in \\\\\"Josie and the Pussycats\\\\\", and on radio as the title character in \\\\\"Meet Corliss Archer\\\\\".\"\\n            ]\\n        ]\\n    ],\\n    \"type\": \"bridge\",\\n    \"level\": \"hard\"\\n}')]\n",
      "\"Node 'generate':\"\n",
      "'\\n---\\n'\n",
      "('Shirley Temple held the government position of United States ambassador to '\n",
      " 'Ghana and to Czechoslovakia, as well as Chief of Protocol of the United '\n",
      " 'States.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Run\n",
    "inputs = {\"questions\": [\"What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\"]}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"generation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi_hop_rag",
   "language": "python",
   "name": "lang_graph_rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
